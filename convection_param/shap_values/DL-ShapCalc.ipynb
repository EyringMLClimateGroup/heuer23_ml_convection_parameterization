{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3492f954-5f38-4ed9-bf2f-418d1c754843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc5e56",
   "metadata": {},
   "source": [
    "Calculation of shap values, parallel if node has more than one gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec50120-fb4f-4b80-be84-136aa5c7d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(<torch.cuda.device at 0x1461009ca500>, 0),\n",
       " (<torch.cuda.device at 0x1460f9a50310>, 1),\n",
       " (<torch.cuda.device at 0x1461009f16f0>, 2),\n",
       " (<torch.cuda.device at 0x1461009f2380>, 3)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "available_gpus = [torch.cuda.device(i) for i in range(torch.cuda.device_count())]\n",
    "print(torch.cuda.is_available())\n",
    "display([(gpu, gpu.idx) for gpu in available_gpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8ab28c-6a2d-4d0f-a80b-23d3636b8886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_train', 'X_val', 'X_test', 'Y_train', 'Y_val', 'Y_test', 'X_expl', 'Y_expl', 'train_coords', 'val_coords', 'test_coords']\n",
      "X_train shape:  torch.Size([1613616, 9, 23])\n",
      "X_val shape:  torch.Size([201702, 9, 23])\n",
      "X_test shape:  torch.Size([201702, 9, 23])\n",
      "Y_train shape:  torch.Size([1613616, 189])\n",
      "Y_val shape:  torch.Size([201702, 189])\n",
      "Y_test shape:  torch.Size([201702, 189])\n",
      "len X_expl 207\n",
      "len Y_expl 189\n"
     ]
    }
   ],
   "source": [
    "# data = np.load('../../Processed/TrainData/R2B5_vcg_20221118-153949.npz')\n",
    "data_path = '../../local_data/TrainData/20230131-171851-R2B5_y13y16_vcg-fluxes_rho_fluct.npz'\n",
    "# data_path = '../../local_data/TrainData/20230210-131835-R2B5_y13y16_vcg-fluxes_rho_fluct_neglect.npz'\n",
    "data = np.load(data_path)\n",
    "print(data.files)\n",
    "\n",
    "X_train, X_val, X_test, Y_train, Y_val, Y_test, X_expl, Y_expl = \\\n",
    "data['X_train'], data['X_val'], data['X_test'], data['Y_train'], data['Y_val'], data['Y_test'], data['X_expl'], data['Y_expl']\n",
    "\n",
    "# Convert Data to torch Tensors and permute to conform to pytorch channels first format\n",
    "transform_to_unet_shape = False\n",
    "if transform_to_unet_shape:\n",
    "    x_transform = nn.Upsample(size=(32), mode='linear')\n",
    "else:\n",
    "    x_transform = nn.Identity()\n",
    "\n",
    "X_train = x_transform(torch.Tensor(X_train).permute(0,2,1))\n",
    "X_val = x_transform(torch.Tensor(X_val).permute(0,2,1))\n",
    "X_test = x_transform(torch.Tensor(X_test).permute(0,2,1))\n",
    "Y_train = torch.Tensor(Y_train)\n",
    "Y_val = torch.Tensor(Y_val)\n",
    "Y_test = torch.Tensor(Y_test)\n",
    "\n",
    "with open('../../local_data/TrainData/20230210-131835-R2B5_y13y16_vcg-fluxes_rho_fluct_neglect_Ymask.pickle', 'rb') as handle:\n",
    "    Y_mask = pickle.load(handle)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('Y_train shape: ', Y_train.shape)\n",
    "print('Y_val shape: ', Y_val.shape)\n",
    "print('Y_test shape: ', Y_test.shape)\n",
    "print('len X_expl', len(X_expl))\n",
    "print('len Y_expl', len(Y_expl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144b757b-8ede-40c2-90a9-3e29ef5117d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True False False False  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "from convection_param.HelperFuncs import unique_unsorted\n",
    "\n",
    "vars_to_neglect = ['qr','qi','qs']\n",
    "# vars_to_neglect = []\n",
    "vars_to_neglect_mask = ~np.isin(unique_unsorted([e[0] for e in X_expl]), vars_to_neglect)\n",
    "print(vars_to_neglect_mask)\n",
    "\n",
    "X_train = X_train[:,vars_to_neglect_mask,:]\n",
    "X_val = X_val[:,vars_to_neglect_mask,:]\n",
    "X_test = X_test[:,vars_to_neglect_mask,:]\n",
    "X_expl = np.array([e for e in X_expl if e[0] not in vars_to_neglect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30d22c7e-aac4-4ee0-b75f-d1e68b590c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Shape of X [N, C, H, W]: torch.Size([1024, 6, 23])\n",
      "Shape of y: torch.Size([1024, 189]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "batch_size_val = 1024\n",
    "# Create data loaders.\n",
    "train_data = TensorDataset(X_train, Y_train)\n",
    "val_data = TensorDataset(X_val, Y_val)\n",
    "test_data = TensorDataset(X_test, Y_test)\n",
    "# torch.save([train_data, val_data, test_data], '../../local_data/TrainData/20230111-165428-R2B5_y13y16_vcg-fluxes_rho_fluct.torch_data')\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size_val, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size_val, shuffle=False)\n",
    "\n",
    "for X, y in val_dataloader:\n",
    "    print('---------------------------------------')\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77c5412-d567-4ebc-8f3e-4afb7087ca2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from convection_param.NetworksTorch import ResDNN, Sequential, Unet, SeqConv\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# model = ResDNN(in_size=23*9,\n",
    "#                out_size=189,\n",
    "#                n_neurons=2048,\n",
    "#                bn=True,\n",
    "#                n_layers_per_block=1,\n",
    "#                n_levels=10,\n",
    "#                activation=nn.ReLU())\n",
    "model = Unet(n_channels=6,\n",
    "                n_classes=8,\n",
    "                output_channels_total=189,\n",
    "                n_levels=2,\n",
    "                n_features=512,\n",
    "                bn1=False,\n",
    "                bn2=False,\n",
    "                column_height=23,\n",
    "                activation=F.leaky_relu,\n",
    "                linear=False)\n",
    "# model = Sequential(X_train.shape[1]*X_train.shape[2], 189, 512, F.relu, True, True)\n",
    "# model = SeqConv(n_channels=X_train.shape[1],\n",
    "#                 n_feature_channels=512,\n",
    "#                 column_height=23,\n",
    "#                 n_hidden=200,\n",
    "#                 n_layers=1,\n",
    "#                 output_dim=189,\n",
    "#                 kernel_size=4).to(device)\n",
    "# model = Convolutional(n_channels=9, n_feature_channels=10, output_dim=189)\n",
    "# print(model)\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f1d6b2-c598-4a14-ab4b-03957615c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tepoch, model, loss_fn, optimizer, epoch, writer=None):\n",
    "    # size = len(dataloader.dataset)\n",
    "    size = tepoch.total\n",
    "    model.train()\n",
    "    # for batch, (X, y) in enumerate(dataloader):\n",
    "    loss_sum = 0\n",
    "    for batch, (X, y) in enumerate(tepoch):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 300 == 0:\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "    if writer:\n",
    "        writer.add_scalar('epoch_loss', loss_sum/size, epoch)\n",
    "\n",
    "def test(dataloader, model, loss_fn, epoch, writer=None):\n",
    "    # size = len(dataloader.dataset) # number of samples\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    if writer:\n",
    "        writer.add_scalar('epoch_loss', test_loss, epoch)\n",
    "    print(f\"Avg val loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6179d68-6907-4e87-95f5-dc3e95a0b621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"../../Models/NewFormat/Torch/20230320-112327R2B5_vlr_unet_adam_lr0.0003_y13y16full_fluxes_prescaledeps1_wqrqstend_worhoprestemp_torch_rhofluctneglect_alldays_woqrqiqs_hpoed_lrelu/\"\n",
    "load_path = os.path.join(model_path, 'model.state_dict')\n",
    "model_name = os.path.basename(load_path).replace('.state_dict','')\n",
    "\n",
    "checkpoint = torch.load(load_path)#, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a73c121-0c3e-400e-acfe-1d6f25d55224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating shap values for seed 745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 16:30:05,547\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculations took 2131.9812400341034 seconds\n",
      "Shap values shape:  (189, 1000, 6, 23)\n",
      "Calculating shap values for seed 3452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 17:05:38,562\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import ray\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "seeds = [745, 3452, 1458, 2489, 646]\n",
    "# seed = 4523455\n",
    "# seed = 42\n",
    "for seed in seeds:\n",
    "    print(f'Calculating shap values for seed {seed}')\n",
    "    npr.seed(seed)\n",
    "    random_idx = npr.choice(X_train.shape[0], size=1500, replace=False)\n",
    "    background_idx = random_idx[:500]\n",
    "    explain_idx = random_idx[500:]\n",
    "\n",
    "    model.to(device)\n",
    "    background = X_train[background_idx].to(device)\n",
    "    X_explain = X_train[explain_idx].to(device)\n",
    "\n",
    "    t0 = time.time()\n",
    "    ray.init(num_cpus=10, num_gpus=4)\n",
    "\n",
    "    a = len(X_explain)//4\n",
    "    b = 2*len(X_explain)//4\n",
    "    c = 3*len(X_explain)//4\n",
    "    d = len(X_explain)\n",
    "\n",
    "    @ray.remote(num_gpus=1)\n",
    "    def solve_a(model, i1, i2):\n",
    "        device = 'cuda:0'\n",
    "        local_model = copy.deepcopy(model)\n",
    "        local_model.to(device)\n",
    "        e = shap.DeepExplainer(local_model, background)\n",
    "        return np.array(e.shap_values(X_explain[i1:i2].to(device)))\n",
    "\n",
    "    a_idx = solve_a.remote(model, 0, a)\n",
    "    b_idx = solve_a.remote(model, a, b)\n",
    "    c_idx = solve_a.remote(model, b, c)\n",
    "    d_idx = solve_a.remote(model, c, d)\n",
    "\n",
    "    a_res, b_res, c_res, d_res = ray.get([a_idx,b_idx,c_idx,d_idx])\n",
    "\n",
    "    ray.shutdown()\n",
    "    print(f'Calculations took {time.time()-t0} seconds')\n",
    "    \n",
    "    shap_values = np.concatenate([a_res,b_res,c_res,d_res], axis=1)\n",
    "    print('Shap values shape: ', shap_values.shape)\n",
    "    \n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    shap_path = os.path.join(model_path, f'shaps_{now}_seed{seed}')\n",
    "    np.savez(shap_path,#f'ShapValues/{now}-{model_name}_seed42',\n",
    "             shap_values=shap_values,\n",
    "             background=background.cpu().numpy(),\n",
    "             X_explain=X_explain.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b848a-dd83-414a-90b4-cfcc9eaba4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (heuer1_py3.8_torch)",
   "language": "python",
   "name": "heuer1_py3.8_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "19c7f42f051f319cb230c51a85006ddf649f5f1aea7671c9ab1191bf8790c429"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
